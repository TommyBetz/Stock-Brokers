{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|      Date|         screen_name|     followers_count|                Time|                text|      favorite_count|       retweet_count|  possibly_sensitive|delete|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|2018-10-01|[oizumix, chabell...|[32, 467, 389, 22...|[2019-03-03, 2019...|[Mon, 01 Oct 2018...|[0, 0, 0, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|[null, null, fals...|    []|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5) # make sure we have Python 3.5+\n",
    "\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "spark = SparkSession.builder.appName('example code').getOrCreate()\n",
    "assert spark.version >= '2.3' # make sure we have Spark 2.3+\n",
    "# spark.sparkContext.setLogLevel('WARN')\n",
    "# sc = spark.sparkContext\n",
    "\n",
    "# # Reading the json data.\n",
    "# df = spark.read.json('./twitter-2018-10-01/2018/10/01/01/55.json.bz2')\n",
    "\n",
    "# Reading the json data.\n",
    "df = spark.read.json('./data/55.json.bz2')\n",
    "\n",
    "# list(df.columns)\n",
    "'''\n",
    "Columns in the dataframe df.\n",
    "['contributors',\n",
    " 'coordinates',\n",
    " 'created_at',\n",
    " 'delete',\n",
    " 'display_text_range',\n",
    " 'entities',\n",
    " 'extended_entities',\n",
    " 'extended_tweet',\n",
    " 'favorite_count',\n",
    " 'favorited',\n",
    " 'filter_level',\n",
    " 'geo',\n",
    " 'id',\n",
    " 'id_str',\n",
    " 'in_reply_to_screen_name',\n",
    " 'in_reply_to_status_id',\n",
    " 'in_reply_to_status_id_str',\n",
    " 'in_reply_to_user_id',\n",
    " 'in_reply_to_user_id_str',\n",
    " 'is_quote_status',\n",
    " 'lang',\n",
    " 'place',\n",
    " 'possibly_sensitive',\n",
    " 'quote_count',\n",
    " 'quoted_status',\n",
    " 'quoted_status_id',\n",
    " 'quoted_status_id_str',\n",
    " 'quoted_status_permalink',\n",
    " 'reply_count',\n",
    " 'retweet_count',\n",
    " 'retweeted',\n",
    " 'retweeted_status',\n",
    " 'source',\n",
    " 'text',\n",
    " 'timestamp_ms',\n",
    " 'truncated',\n",
    " 'user',\n",
    " 'withheld_in_countries']\n",
    "'''\n",
    "\n",
    "# Keeping only the required fields.\n",
    "df_fields_filtered = df.select(df['user'], df['timestamp_ms'], df['lang'], df['text'], df['favorite_count'], df['retweet_count'], df['possibly_sensitive'], df['delete'])\n",
    "\n",
    "# Keeping only the tweets in the english language.\n",
    "df_lang_fields_filtered = df_fields_filtered.filter(df['lang'] == 'en')\n",
    "\n",
    "# Dropping the language column.\n",
    "df_lang_fields_filtered = df_lang_fields_filtered.drop('lang')\n",
    "\n",
    "# Filtering the records whose timestamp_ms field is null.\n",
    "df_time_lang_fields_filtered = df_lang_fields_filtered.filter(df_lang_fields_filtered['timestamp_ms'].isNotNull())\n",
    "\n",
    "'''\n",
    "Structure of the user column: contributors_enabled, created_at, default_profile, \n",
    "    default_profile_image, description, favourites_count, follow_request_sent, followers_count, \n",
    "    following, friends_count, geo_enabled, id, id_str, is_translator, lang, listed_count, \n",
    "    location, name, notifications, profile_background_color, profile_background_image_url, \n",
    "    profile_background_image_url_https, profile_background_tile, profile_banner_url, \n",
    "    profile_image_url, profile_image_url_https, profile_link_color, profile_sidebar_border_color, \n",
    "    profile_sidebar_fill_color, profile_text_color, profile_use_background_image, protected, \n",
    "    screen_name, statuses_count, time_zone, translator_type, url, utc_offset, verified.\n",
    "'''\n",
    "\n",
    "# Extracting the screen_name and followers_count from the user column and deleting the user column.\n",
    "df_user_time_lang_fields_filtered = df_time_lang_fields_filtered.withColumn('screen_name', df_time_lang_fields_filtered['user']['screen_name'])\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.withColumn('followers_count', df_user_time_lang_fields_filtered['user']['followers_count'])\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.drop('user')\n",
    "\n",
    "@functions.udf(returnType = types.DateType())\n",
    "def convert_timestamp_to_date(timestamp_in_ms):\n",
    "    date = datetime.datetime.fromtimestamp(float(timestamp_in_ms)/1000).strftime('%Y-%m-%d')\n",
    "    return parse(date)\n",
    "\n",
    "@functions.udf(returnType = types.DateType())\n",
    "def convert_timestamp_to_time(timestamp_in_ms):\n",
    "    time = datetime.datetime.fromtimestamp(float(timestamp_in_ms)/1000).strftime('%H:%M:%S.%f')\n",
    "    return parse(time)\n",
    "\n",
    "# Converting the timestamp in milliseconds to date.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.withColumn('Date', convert_timestamp_to_date(df_user_time_lang_fields_filtered['timestamp_ms']))\n",
    "\n",
    "# Converting the timestamp in milliseconds to time.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.withColumn('Time', convert_timestamp_to_time(df_user_time_lang_fields_filtered['timestamp_ms']))\n",
    "\n",
    "# Dropping the timestamp_ms column.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.drop('timestamp_ms')\n",
    "\n",
    "# Reordering the columns.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.select('Date', 'screen_name', 'followers_count', 'Time', 'text', 'favorite_count', 'retweet_count', 'possibly_sensitive', 'delete')\n",
    "\n",
    "# # To check the datatypes of the columns.\n",
    "# print(df_time_user_lang_fields_filtered.dtypes)\n",
    "'''\n",
    "[('Date', 'date'), ('screen_name', 'string'), ('followers_count', 'bigint'),\n",
    "('Time', 'date'), ('text', 'string'), ('favorite_count', 'bigint'),\n",
    "('retweet_count', 'bigint'), ('possibly_sensitive', 'boolean'),\n",
    "('delete',\n",
    "'struct<status:struct<id:bigint,id_str:string,user_id:bigint,user_id_str:string>,timestamp_ms:string>')]\n",
    "'''\n",
    "\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.withColumn('possibly_sensitive', df_user_time_lang_fields_filtered['possibly_sensitive'].cast(types.StringType()))\n",
    "\n",
    "# # To check the datatypes of the columns.\n",
    "# print(df_user_time_lang_fields_filtered.dtypes)\n",
    "'''\n",
    "[('Date', 'date'), ('screen_name', 'string'), ('followers_count', 'bigint'),\n",
    "('Time', 'date'), ('text', 'string'), ('favorite_count', 'bigint'),\n",
    "('retweet_count', 'bigint'), ('possibly_sensitive', 'string'),\n",
    "('delete',\n",
    "'struct<status:struct<id:bigint,id_str:string,user_id:bigint,user_id_str:string>,timestamp_ms:string>')]\n",
    "'''\n",
    "\n",
    "# https://stackoverflow.com/questions/45065636/pyspark-how-to-fillna-values-in-dataframe-for-specific-columns\n",
    "# https://stackoverflow.com/questions/42312042/how-to-replace-all-null-values-of-a-dataframe-in-pyspark\n",
    "null_replace_dictionary = { 'screen_name':'null', 'text':'null', 'possibly_sensitive':'null',\n",
    "                            'followers_count':0, 'favorite_count':0, 'retweet_count':0}\n",
    "\n",
    "# Replacing the null values in the dataframe so that when we use collect_list we can retain the mapping.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.na.fill(null_replace_dictionary)\n",
    "\n",
    "# Grouping the tweets by date and aggregating the rest of the columns with collect_list.\n",
    "df_user_time_lang_fields_filtered = df_user_time_lang_fields_filtered.groupby('Date').agg(\n",
    "                                    functions.collect_list('screen_name').alias('screen_name'),                                        \n",
    "                                    functions.collect_list('followers_count').alias('followers_count'),\n",
    "                                    functions.collect_list('Time').alias('Time'),\n",
    "                                    functions.collect_list('text').alias('text'),\n",
    "                                    functions.collect_list('favorite_count').alias('favorite_count'),\n",
    "                                    functions.collect_list('retweet_count').alias('retweet_count'),\n",
    "                                    functions.collect_list('possibly_sensitive').alias('possibly_sensitive'),\n",
    "                                    functions.collect_list('delete').alias('delete')\n",
    "                                    )\n",
    "\n",
    "\n",
    "# To check the datatypes of the columns.\n",
    "# print(df_user_time_lang_fields_filtered.dtypes)\n",
    "'''\n",
    "[('Date', 'date'),\n",
    " ('screen_name', 'array<string>'),\n",
    " ('followers_count', 'array<bigint>'),\n",
    " ('Time', 'array<date>'),\n",
    " ('text', 'array<string>'),\n",
    " ('favorite_count', 'array<bigint>'),\n",
    " ('retweet_count', 'array<bigint>'),\n",
    " ('possibly_sensitive', 'array<boolean>'),\n",
    " ('delete',\n",
    "  'array<struct<status:struct<id:bigint,id_str:string,user_id:bigint,user_id_str:string>,timestamp_ms:string>>')]\n",
    "'''\n",
    "\n",
    "# To check the size of the columns.\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['screen_name'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['followers_count'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['Time'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['text'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['favorite_count'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['retweet_count'])).show()\n",
    "# df_user_time_lang_fields_filtered.select(functions.size(df_user_time_lang_fields_filtered['possibly_sensitive'])).show()\n",
    "\n",
    "# # To check the values of the columns.\n",
    "# df_user_time_lang_fields_filtered.select(df_user_time_lang_fields_filtered['Date']).distinct().show()\n",
    "\n",
    "df_user_time_lang_fields_filtered.show()\n",
    "\n",
    "\n",
    "# list(df.toPandas().columns.values)\n",
    "# df = df.toPandas()\n",
    "# df.head(50).to_csv('sdvsdvdsvdsv.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# df.toPandas().head(5)\n",
    "\n",
    "# # add more functions as necessary\n",
    "\n",
    "# def main(inputs, output):\n",
    "#     # main logic starts here\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     inputs = sys.argv[1]\n",
    "#     output = sys.argv[2]\n",
    "#     main(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
